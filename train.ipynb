{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader as DataLoader\n",
    "from torchvision.transforms import Compose, Resize, ToTensor\n",
    "from matplotlib import pyplot as plt\n",
    "from melSpecDataset import MelSpecDataset\n",
    "import basic_model as net0\n",
    "import christ as net1\n",
    "\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import ImageFolder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set run choices\n",
    "loss_plot = True\n",
    "verbose = True\n",
    "epoch_save = False\n",
    "\n",
    "# set variables\n",
    "train_dir = './splitdata/training'\n",
    "val_dir = './splitdata/testing'\n",
    "#test_dir = './images/testing/'\n",
    "gamma = 1\n",
    "num_epochs = 100\n",
    "batch_size = 64\n",
    "learning_rate = 0.0001\n",
    "weight_decay = 1e-4\n",
    "rho = 0.9\n",
    "eps = 1e-06"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#device = \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#need to change based on model name\n",
    "#this calls the constructor of model class setting the choosen model for the run\n",
    "################################################################################\n",
    "\n",
    "#model = net0.GenreClassificationANN()\n",
    "model = net1.MusicClassNet()\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "################################################################################\n",
    "# dataloader\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((250, 250)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# training\n",
    "train_dataset = MelSpecDataset(train_dir, transform=transform)\n",
    "data_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# validation\n",
    "val_dataset = MelSpecDataset(val_dir, transform)\n",
    "val_loader = DataLoader(dataset=val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# model optimizer\n",
    "optimizer = torch.optim.Adadelta(model.parameters(), lr=learning_rate, rho=rho, eps=eps, weight_decay=weight_decay )\n",
    "\n",
    "# model scheduler\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=6, verbose=True)\n",
    "\n",
    "# loss function\n",
    "loss_function = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, val_loader, loss_function, device):\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for melspecs, labels in val_loader:\n",
    "            audios = melspecs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            output = model(audios)\n",
    "\n",
    "            # Calculate the loss\n",
    "            loss = loss_function(output, labels)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "            # Calculate accuracy (you can customize this based on your task)\n",
    "            predictions = torch.argmax(output, dim=1)\n",
    "            total_correct += (predictions == labels).sum().item()\n",
    "            total_samples += labels.size(0)\n",
    "\n",
    "    # Calculate average validation loss\n",
    "    avg_val_loss = val_loss / len(val_loader)\n",
    "\n",
    "    # Calculate accuracy\n",
    "    accuracy = total_correct / total_samples\n",
    "\n",
    "    return avg_val_loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    model.train()\n",
    "    model.to(device)\n",
    "\n",
    "    epoch_losses = []\n",
    "    epoch_losses_val = []\n",
    "    n_batches_train = len(data_loader)\n",
    "    n_batches_val = len(val_loader)\n",
    "\n",
    "    for epoch in range(1, num_epochs+1):\n",
    "        batch_loss = 0\n",
    "        print(f'Epoch #{epoch}, Start Time: {datetime.datetime.now()}')\n",
    "\n",
    "        #training\n",
    "        model.train()\n",
    "        for melspecs, labels in data_loader:\n",
    "            \n",
    "            #print(melspecs.shape)\n",
    "            #print(labels)\n",
    "            audios = melspecs.to(device)\n",
    "            labels = labels.to(device)\n",
    "        \n",
    "            # calculate losses and call call model\n",
    "            output = model(audios)\n",
    "            \n",
    "            # batch loss\n",
    "            loss = loss_function(output, labels)\n",
    "            batch_loss += loss.item()\n",
    "\n",
    "            # backpropogation\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # save epoch loss\n",
    "        epoch_losses += [batch_loss/n_batches_train]\n",
    "        scheduler.step(epoch_losses[-1])\n",
    "        \n",
    "        \n",
    "        #validation\n",
    "        loss_val = 0\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for melspecs, labels in val_loader:\n",
    "                audios = melspecs.to(device)\n",
    "                labels = labels.to(device)\n",
    " \n",
    "                output = model(audios)\n",
    "            \n",
    "                # calculate losses\n",
    "                loss = loss_function(output, labels)\n",
    "                loss_val += loss.item()\n",
    "    \n",
    "        # Record the validation loss and accuracy\n",
    "        epoch_losses_val += [loss_val / n_batches_val]\n",
    "        \n",
    "        #epoch_accuracies.append(val_accuracy)\n",
    "        \n",
    "        if verbose:\n",
    "            print(f'Epoch: #{epoch}, Loss: {epoch_losses[epoch-1]}')\n",
    "            print(f'Epoch: #{epoch}, Val_Loss: {epoch_losses_val[epoch - 1]}')\n",
    "\n",
    "        if epoch_save:\n",
    "            model_folder_dir = './temp_models'\n",
    "            if not os.path.isdir(model_folder_dir):\n",
    "                os.mkdir(model_folder_dir)\n",
    "\n",
    "             # save temp model\n",
    "            try:\n",
    "                temp_model_path = model_folder_dir + '/' + str(datetime.datetime.now()) + '_epoch' + str(epoch) + '.pth'\n",
    "                torch.save(model.state_dict(), temp_model_path)\n",
    "                if verbose:\n",
    "                    print(f'Saved model for epoch {epoch} @{temp_model_path}')\n",
    "            except:\n",
    "                print('Epoch model save failed')\n",
    "\n",
    "    # save final model parameters   \n",
    "    torch.save(model.state_dict(), f'model.pth')\n",
    "\n",
    "    # save final loss plot\n",
    "    if not os.path.exists(\"./plots\"):\n",
    "        os.makedirs(\"./plots\")\n",
    "    timestamp = datetime.datetime.now().strftime('%Y-%m-%d_%H-%M-%S')\n",
    "    # generate_loss_plot(epoch_losses, f'./plots/loss_plot_{timestamp}.png', show_plot=loss_plot)\n",
    "    generate_loss_plot_with_val(epoch_losses, epoch_losses_val, f'./plots/loss_plot_{timestamp}.png', show_plot=loss_plot)\n",
    "\n",
    "def generate_loss_plot(loss, file_loc, show_plot=False):\n",
    "    epochs = list(range(1, len(loss)+1))\n",
    "    plt.plot(epochs, loss)\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Epoch vs Loss')\n",
    "    plt.savefig(file_loc)\n",
    "    if show_plot:\n",
    "        plt.show()\n",
    "    plt.close()\n",
    "\n",
    "def generate_loss_plot_with_val(train_loss, val_loss, file_loc, show_plot=False): # loss plot with validation\n",
    "    epochs = list(range(1, len(train_loss)+1))\n",
    "    plt.plot(epochs, train_loss, label = \"Training Loss\")\n",
    "    plt.plot(epochs, val_loss, label= \"Validation Loss\")\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Epoch vs Loss')\n",
    "    plt.legend()\n",
    "    plt.savefig(file_loc)\n",
    "    \n",
    "    if show_plot:\n",
    "        plt.show()\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
